{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfbefdf2-399f-4bf8-ab1d-7e1a7b6a3a34",
   "metadata": {},
   "source": [
    "## Reproduce the results using the models trained and stored in the models folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55ae034c-6354-4589-8ed6-dcb94b4b7518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dd27b8b-97a0-4130-8047-b359dd24d7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path='$HOME/Datasets/QuoraQuestionPairs/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "547bbb76-58ee-4b90-bf0a-03a9104f9064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_df.shape= (15363, 6)\n",
      "test_df.shape= (16172, 6)\n"
     ]
    }
   ],
   "source": [
    "# Create validation and test partitions\n",
    "quora_df = pd.read_csv(\"$HOME/Datasets/QuoraQuestionPairs/quora_data.csv\")\n",
    "A_df, test_df = sklearn.model_selection.train_test_split(quora_df, test_size=0.05, random_state=123)\n",
    "train_df, val_df = sklearn.model_selection.train_test_split(A_df, test_size=0.05)\n",
    "print('val_df.shape=',val_df.shape)\n",
    "print('test_df.shape=',test_df.shape)\n",
    "\n",
    "y_val = val_df[\"is_duplicate\"].values\n",
    "\n",
    "# cast to list taking care of nans:\n",
    "q1_val =  cast_list_as_strings(list(val_df[\"question1\"]))\n",
    "q2_val =  cast_list_as_strings(list(val_df[\"question2\"]))\n",
    "q1_test  =  cast_list_as_strings(list(test_df[\"question1\"]))\n",
    "q2_test  =  cast_list_as_strings(list(test_df[\"question2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a89cdfd-6fdf-4d12-aad0-c557aeb339d4",
   "metadata": {},
   "source": [
    "## 1. Load the teachers baseline model and print accuracy:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b4ad4-686d-4ec7-bac7-9bba4e728c5b",
   "metadata": {},
   "source": [
    "Load Teachers baseline ad the vectoirizer used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f392c1c-2686-4f12-9146-c7c51616bb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from models/teacher_baseline.pkl\n",
      "Model loaded from models/count_vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "logistic = load_model(path=models_path, filename=\"teacher_baseline.pkl\")\n",
    "count_vectorizer = load_model(path=models_path, filename=\"count_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d2f336-ed7e-4cca-8a49-406c391210ff",
   "metadata": {},
   "source": [
    "And now evaluate on the VALIDATION set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18151bfd-2ed5-43a4-ab2c-7fe7bd5a8e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with count vectoriser: 0.8082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#get the validation feature for the count vectorizer:\n",
    "X_val_q1q2 = get_features_from_df(val_df, count_vectorizer)\n",
    "\n",
    "#accuracy of the regr with count vectorizer\n",
    "y_pred = logistic.predict(X_val_q1q2)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy with count vectoriser: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84ec611-d8c7-49e0-a76b-c4bf26504ce1",
   "metadata": {},
   "source": [
    "## 2. Using custom TFIDF_Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8339d1-400e-4442-b0bc-9a728690009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from models/custom_tfidf_logreg.pkl\n",
      "Model loaded from models/custom_tfidf_vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "#load model and vectorizer:\n",
    "logistic2 = load_model(models_path, \"custom_tfidf_logreg.pkl\")\n",
    "custom_vectorizer = load_model(models_path, \"custom_tfidf_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e1ec567-3350-4060-b6ad-3be0bdeec91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy new approach with custom TFIDF vectorizer: 0.8563\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_val_q1q2_tfidf = get_features_from_df_tfidf(val_df, custom_vectorizer)\n",
    "\n",
    "y_pred = logistic2.predict(X_val_q1q2_tfidf)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy new approach with custom TFIDF vectorizer: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08220ed8-7daf-4616-ba4f-e7e4b6d627e4",
   "metadata": {},
   "source": [
    "## 3. Using built-in TFIDF vectorizer on charecter level with 4-grams, and a cosinus similarity between the pairs metric feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5284fc2-2ddc-438c-9d72-cca4b1171949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from models/tfidf_4_char_gram_logreg.pkl\n",
      "Model loaded from models/tfidf_vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "logistic4 = load_model(models_path, \"tfidf_4_char_gram_logreg.pkl\")\n",
    "tfidf_vectorizer = load_model(models_path, \"tfidf_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40a59b95-39b6-4d6b-b605-364e33428b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy new approach with custom TFIDF vectorizer: 0.8325\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from Utils import *\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "val_df['char_ngram_sim'] = val_df.apply(lambda row: char_ngram_similarity(row['question1'], row['question2'], tfidf_vectorizer), axis=1)\n",
    "char_sim_sparse = sparse.csr_matrix(val_df['char_ngram_sim'].values).T  # make it column vector\n",
    "\n",
    "X_val_q1q2_bi_tfidf = get_features_from_df_tfidf(val_df, tfidf_vectorizer)\n",
    "\n",
    "X_train_combined = hstack([X_val_q1q2_bi_tfidf, char_sim_sparse])\n",
    "\n",
    "y_pred = logistic4.predict(X_train_combined)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy new approach with TFIDF vectorizer and 4-gram cosin-similarity: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf139f1-b724-45f0-99e2-3da10ad85409",
   "metadata": {},
   "source": [
    "## 4. Using log regression with built in TFIDF, 4-gram character cosin similarity feature and feature whether it question starts with specific question word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bce8e98f-ca85-4fa9-99af-1971d977149c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from models/tfidf_5_char_gram_word_starts_logreg.pkl\n",
      "Model loaded from models/scaler_tfidf_5_char_gram_word_starts_logreg.pkl\n",
      "Model loaded from models/tfidf_vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "logistic5 = load_model(models_path, \"tfidf_5_char_gram_word_starts_logreg.pkl\")\n",
    "scaler = load_model(models_path, \"scaler_tfidf_5_char_gram_word_starts_logreg.pkl\")\n",
    "tfidf_vectorizer = load_model(models_path, \"tfidf_vectorizer.pkl\")\n",
    "import pickle\n",
    "# We need them in the same order as in training!!!\n",
    "with open(models_path + '/feature_cols_train_start_words.pkl', 'rb') as f:\n",
    "    feature_cols_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b7bdf65-3054-42a5-be4b-683c72b0bd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q1_starts_with_how', 'q1_starts_with_can', 'q1_starts_with_what', 'q1_starts_with_why', 'q1_starts_with_are', 'q1_starts_with_do', 'q1_starts_with_does', 'q1_starts_with_is', 'q1_starts_with_should', 'q1_starts_with_could', 'q2_starts_with_how', 'q2_starts_with_can', 'q2_starts_with_what', 'q2_starts_with_why', 'q2_starts_with_are', 'q2_starts_with_do', 'q2_starts_with_does', 'q2_starts_with_is', 'q2_starts_with_should', 'q2_starts_with_could']\n",
      "        q1_starts_with_how  q1_starts_with_can  q1_starts_with_what  \\\n",
      "53593                    0                   0                    0   \n",
      "100923                   0                   0                    1   \n",
      "226707                   1                   0                    0   \n",
      "25127                    0                   1                    0   \n",
      "15382                    0                   0                    0   \n",
      "...                    ...                 ...                  ...   \n",
      "249858                   0                   0                    0   \n",
      "9936                     0                   0                    1   \n",
      "166841                   1                   0                    0   \n",
      "202575                   0                   0                    1   \n",
      "75037                    0                   0                    0   \n",
      "\n",
      "        q1_starts_with_why  q1_starts_with_are  q1_starts_with_do  \\\n",
      "53593                    0                   0                  0   \n",
      "100923                   0                   0                  0   \n",
      "226707                   0                   0                  0   \n",
      "25127                    0                   0                  0   \n",
      "15382                    0                   0                  0   \n",
      "...                    ...                 ...                ...   \n",
      "249858                   0                   0                  0   \n",
      "9936                     0                   0                  0   \n",
      "166841                   0                   0                  0   \n",
      "202575                   0                   0                  0   \n",
      "75037                    1                   0                  0   \n",
      "\n",
      "        q1_starts_with_does  q1_starts_with_is  q1_starts_with_should  \\\n",
      "53593                     0                  0                      0   \n",
      "100923                    0                  0                      0   \n",
      "226707                    0                  0                      0   \n",
      "25127                     0                  0                      0   \n",
      "15382                     0                  0                      0   \n",
      "...                     ...                ...                    ...   \n",
      "249858                    0                  0                      0   \n",
      "9936                      0                  0                      0   \n",
      "166841                    0                  0                      0   \n",
      "202575                    0                  0                      0   \n",
      "75037                     0                  0                      0   \n",
      "\n",
      "        q1_starts_with_could  q2_starts_with_how  q2_starts_with_can  \\\n",
      "53593                      0                   0                   0   \n",
      "100923                     0                   0                   0   \n",
      "226707                     0                   1                   0   \n",
      "25127                      0                   0                   0   \n",
      "15382                      0                   1                   0   \n",
      "...                      ...                 ...                 ...   \n",
      "249858                     0                   0                   0   \n",
      "9936                       0                   0                   0   \n",
      "166841                     0                   0                   0   \n",
      "202575                     0                   0                   0   \n",
      "75037                      0                   0                   0   \n",
      "\n",
      "        q2_starts_with_what  q2_starts_with_why  q2_starts_with_are  \\\n",
      "53593                     1                   0                   0   \n",
      "100923                    1                   0                   0   \n",
      "226707                    0                   0                   0   \n",
      "25127                     0                   0                   0   \n",
      "15382                     0                   0                   0   \n",
      "...                     ...                 ...                 ...   \n",
      "249858                    1                   0                   0   \n",
      "9936                      1                   0                   0   \n",
      "166841                    1                   0                   0   \n",
      "202575                    1                   0                   0   \n",
      "75037                     1                   0                   0   \n",
      "\n",
      "        q2_starts_with_do  q2_starts_with_does  q2_starts_with_is  \\\n",
      "53593                   0                    0                  0   \n",
      "100923                  0                    0                  0   \n",
      "226707                  0                    0                  0   \n",
      "25127                   0                    0                  0   \n",
      "15382                   0                    0                  0   \n",
      "...                   ...                  ...                ...   \n",
      "249858                  0                    0                  0   \n",
      "9936                    0                    0                  0   \n",
      "166841                  0                    0                  0   \n",
      "202575                  0                    0                  0   \n",
      "75037                   0                    0                  0   \n",
      "\n",
      "        q2_starts_with_should  q2_starts_with_could  \n",
      "53593                       0                     0  \n",
      "100923                      0                     0  \n",
      "226707                      0                     0  \n",
      "25127                       0                     0  \n",
      "15382                       0                     0  \n",
      "...                       ...                   ...  \n",
      "249858                      0                     0  \n",
      "9936                        0                     0  \n",
      "166841                      0                     0  \n",
      "202575                      0                     0  \n",
      "75037                       0                     0  \n",
      "\n",
      "[15363 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# start_words = ['how', 'can', 'what', 'why', 'are', 'do', 'does', 'is', 'should', 'could']\n",
    "\n",
    "start_feats_q1 = val_df['question1'].apply(lambda x: pd.Series(starts_with_indicator(x)))\n",
    "start_feats_q1.columns = [f'q1_{col}' for col in start_feats_q1.columns]\n",
    "\n",
    "start_feats_q2 = val_df['question2'].apply(lambda x: pd.Series(starts_with_indicator(x)))\n",
    "start_feats_q2.columns = [f'q2_{col}' for col in start_feats_q2.columns]\n",
    "\n",
    "val_df = pd.concat([val_df, start_feats_q1, start_feats_q2], axis=1)\n",
    "\n",
    "#print(feature_cols_train)\n",
    "val_numeric_features = val_df[feature_cols_train]\n",
    "val_numeric_features = val_numeric_features[feature_cols_train]\n",
    "#print(val_numeric_features)\n",
    "\n",
    "# Scale numeric features before combining with sparse ones\n",
    "\n",
    "numeric_scaled = scaler.transform(val_numeric_features)\n",
    "numeric_sparse = sparse.csr_matrix(numeric_scaled)\n",
    "\n",
    "val_df['char_ngram_sim'] = val_df.apply(lambda row: char_ngram_similarity(row['question1'], row['question2'], tfidf_vectorizer), axis=1)\n",
    "char_sim_sparse = sparse.csr_matrix(val_df['char_ngram_sim'].values).T  # make it column vector\n",
    "\n",
    "X_val_q1q2_bi_tfidf = get_features_from_df_tfidf(val_df, tfidf_vectorizer)\n",
    "\n",
    "# we're using the 4-gram \n",
    "X_train_combined = hstack([X_val_q1q2_bi_tfidf, char_sim_sparse, numeric_sparse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c879290-893a-4966-a767-98121a928c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy new approach with TFIDF vectorizer and 4-gram cosin-similarity and feature for start word: 0.6071\n"
     ]
    }
   ],
   "source": [
    "y_pred = logistic5.predict(X_train_combined)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy new approach with TFIDF vectorizer and 4-gram cosin-similarity and feature for start word: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837381c8-79eb-4001-a04b-3c9c24ba07b5",
   "metadata": {},
   "source": [
    "## 5. Use Jackard similarity and TFIDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9229f2e1-572c-49c6-97b7-55de5c730d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from models/tfidf_jackard_logreg.pkl\n",
      "Model loaded from models/tfidf_vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "logistic6 = load_model(models_path, \"tfidf_jackard_logreg.pkl\")\n",
    "tfidf_vectorizer = load_model(models_path, \"tfidf_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e7fbd6a-ce6d-44a5-88f0-8cb58ef5d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['jaccard_sim'] = val_df.apply(lambda row: jaccard_similarity(row['question1'], row['question2']), axis=1)\n",
    "\n",
    "X_val_q1q2_bi_tfidf = get_features_from_df_tfidf(val_df, tfidf_vectorizer)\n",
    "\n",
    "# we're using the 4-gram \n",
    "X_train_combined = hstack([X_val_q1q2_bi_tfidf, val_df['jaccard_sim'].values.reshape(-1, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db23314a-d71d-490f-8b18-3f39cd8f04f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy new approach with TFIDF vectorizer and 4-gram cosin-similarity and feature for start word: 0.8200\n"
     ]
    }
   ],
   "source": [
    "y_pred = logistic6.predict(X_train_combined)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy new approach with TFIDF vectorizer and Jackard similarity: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ce332f-dc65-4628-964b-83c6d6b7d0e0",
   "metadata": {},
   "source": [
    "## 6. Custom TFIDF and Jackard similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4e89e4e1-51e6-4831-88e5-be403e2495e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from models/custom_tfidf_jackard_logreg.pkl\n",
      "Model loaded from models/custom_tfidf_vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "logistic7 = load_model(models_path, \"custom_tfidf_jackard_logreg.pkl\")\n",
    "custom_vectorizer = load_model(models_path, \"custom_tfidf_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "58417720-393a-4d8b-9c1f-54ce90320bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['jaccard_sim'] = val_df.apply(lambda row: jaccard_similarity(row['question1'], row['question2']), axis=1)\n",
    "\n",
    "X_val_q1q2_tfidf = get_features_from_df_tfidf(val_df, custom_vectorizer)\n",
    "\n",
    "# we're using the 4-gram \n",
    "X_train_combined = hstack([X_val_q1q2_tfidf, val_df['jaccard_sim'].values.reshape(-1, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "000fffac-10ef-463c-a7a7-1a9ac05a66fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy new approach with custom TFIDF vectorizer and Jackard similarity: 0.8735\n"
     ]
    }
   ],
   "source": [
    "y_pred = logistic7.predict(X_train_combined)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy new approach with custom TFIDF vectorizer and Jackard similarity: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72719c5-4b2b-412e-9c65-89203648bcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
