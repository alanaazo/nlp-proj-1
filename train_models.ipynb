{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c18208-81b5-4912-9e25-78f3b5100971",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notebook to train the models and store them in the models folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "563d1430-59b9-43c6-9170-7ae2e46abe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23e7895c-fed7-421f-8b01-eae9ca6e357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to models directory: (TODO: change to the teacher's requirement)\n",
    "models_path=\"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43183a90-5a0a-4cae-87af-8ca8eda69c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape= (291897, 6)\n",
      "lenght of all questions: 583794\n"
     ]
    }
   ],
   "source": [
    "#Load the dataset:\n",
    "# Create training, validation and test partitions\n",
    "quora_df = pd.read_csv(\"./quora_data.csv\")\n",
    "A_df, test_df = sklearn.model_selection.train_test_split(quora_df, test_size=0.05, random_state=123)\n",
    "train_df, val_df = sklearn.model_selection.train_test_split(A_df, test_size=0.05)\n",
    "print('train_df.shape=',train_df.shape)\n",
    "\n",
    "# cast to list taking care of nans:\n",
    "q1_train =  cast_list_as_strings(list(train_df[\"question1\"]))\n",
    "q2_train =  cast_list_as_strings(list(train_df[\"question2\"]))\n",
    "\n",
    "all_questions = q1_train + q2_train\n",
    "\n",
    "print(f'lenght of all questions: {len(all_questions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf7b443-9e60-4751-803d-4f895958b940",
   "metadata": {},
   "source": [
    "## 1. Train and save model of Teacher for Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e875983-e706-4408-b24b-8e9932f9f64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/teacher_baseline.pkl\n",
      "Model saved to models/count_vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "#train and save the teacher's baseline with count vectorizer:\n",
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer(ngram_range=(1,1))\n",
    "count_vectorizer.fit(all_questions)\n",
    "\n",
    "X_tr_q1q2 = get_features_from_df(train_df, count_vectorizer)\n",
    "\n",
    "logistic = sklearn.linear_model.LogisticRegression(solver=\"liblinear\",\n",
    "                                                   random_state=123)\n",
    "y_train = train_df[\"is_duplicate\"].values\n",
    "logistic.fit(X_tr_q1q2, y_train)\n",
    "\n",
    "save_model(logistic, models_path, \"teacher_baseline.pkl\")\n",
    "save_model(count_vectorizer, models_path, \"count_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3f539a-da6f-4f5d-89eb-54817e39c80a",
   "metadata": {},
   "source": [
    "## 2. Train and save model using custom TFIDF vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e5f6b26-e063-42a5-b6d8-02775e1f1b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit custom vectorizer on ALL questions...\n",
      "Transformin the question1 and question2 columns from the train data by applying the fitted vectorizerand putting them in a sparce matrix...\n",
      "Model saved to models/custom_tfidf_logreg.pkl\n",
      "Model saved to models/custom_tfidf_vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "print('fit custom vectorizer on ALL questions...')\n",
    "custom_vectorizer = TFIDF_Vectorizer()\n",
    "custom_vectorizer.fit(all_questions)\n",
    "\n",
    "print('Transforming the question1 and question2 columns from the train data \\\n",
    "by applying the fitted vectorizer\\\n",
    "and putting them in a sparce matrix...')\n",
    "X_tr_q1q2_tfidf = get_features_from_df_tfidf(train_df, custom_vectorizer)\n",
    "y_train = train_df[\"is_duplicate\"].values\n",
    "\n",
    "# regression similoar to bvaseline to see if tfidf makes things better:\n",
    "logistic2 = sklearn.linear_model.LogisticRegression(solver=\"liblinear\",\n",
    "                                                   random_state=123)\n",
    "logistic2.fit(X_tr_q1q2_tfidf, y_train)\n",
    "\n",
    "save_model(logistic2, models_path, \"custom_tfidf_logreg.pkl\")\n",
    "save_model(custom_vectorizer, models_path, \"custom_tfidf_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6465bc64-d33e-4564-82d2-b03c5e2da676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
